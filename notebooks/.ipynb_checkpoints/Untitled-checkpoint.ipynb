{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3c20a5-aa94-47b9-8e67-de46b587a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[Info] 成功讀取訓練資料，共 4377102 筆\n",
      "[Info] 成功讀取站點資訊檔\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 檢查裝置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 設定路徑 ---\n",
    "data_path = '../data/processed/youbike_weather_merged.csv'\n",
    "info_path = '../data/raw/station_info.csv'\n",
    "\n",
    "# 1. 讀取主訓練資料\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['record_time'] = pd.to_datetime(df['record_time'])\n",
    "    print(f\"[Info] 成功讀取訓練資料，共 {len(df)} 筆\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"找不到訓練資料：{data_path}\")\n",
    "\n",
    "# 2. 讀取站點資訊 (用來查中文站名)\n",
    "if os.path.exists(info_path):\n",
    "    # 防呆：嘗試用 Tab 分隔讀取，失敗則用逗號\n",
    "    try:\n",
    "        df_info = pd.read_csv(info_path, sep='\\t')\n",
    "        if len(df_info.columns) <= 1: df_info = pd.read_csv(info_path)\n",
    "    except:\n",
    "        df_info = pd.read_csv(info_path)\n",
    "        \n",
    "    # 建立對照表：station_no -> 中文名稱 (去除 YouBike2.0_ 前綴)\n",
    "    name_map = dict(zip(df_info['station_no'].astype(str), df_info['name_tw'].str.replace('YouBike2.0_', '')))\n",
    "    print(f\"[Info] 成功讀取站點資訊檔\")\n",
    "else:\n",
    "    print(f\"[Warning] 找不到站點資訊檔，將使用預設名稱\")\n",
    "    name_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bc5ffc-bba3-42c8-bb15-500be4c09ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 特徵工程完成：已新增 'Rain_Cat' (降雨分級)\n",
      "          record_time  rain  Rain_Cat\n",
      "0 2025-12-09 21:31:29   0.0         0\n",
      "1 2025-12-09 21:31:29   0.0         0\n",
      "2 2025-12-09 21:31:29   0.0         0\n",
      "3 2025-12-09 21:31:29   0.0         0\n",
      "4 2025-12-09 21:31:29   0.0         0\n"
     ]
    }
   ],
   "source": [
    "# --- 定義降雨分級函數 ---\n",
    "def get_rain_category(val):\n",
    "    if val == 0: return 0      # 無雨\n",
    "    elif val <= 2: return 1    # 毛毛雨 (Drizzle)\n",
    "    elif val <= 10: return 2   # 小雨/中雨 (Rain)\n",
    "    else: return 3             # 大雨 (Heavy)\n",
    "\n",
    "# 確保 rain 欄位無空值\n",
    "df['rain'] = df['rain'].fillna(0)\n",
    "\n",
    "# 應用函數產生新特徵\n",
    "df['Rain_Cat'] = df['rain'].apply(get_rain_category)\n",
    "\n",
    "print(\" 特徵工程完成：已新增 'Rain_Cat' (降雨分級)\")\n",
    "print(df[['record_time', 'rain', 'Rain_Cat']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ce21cb-3fdc-428f-ac4d-5a1c66f0fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發現行政區: ['大安區' '大同區' '士林區' '文山區' '中正區' '中山區' '內湖區' '北投區' '松山區' '南港區' '信義區' '萬華區'\n",
      " '臺大公館校區']\n",
      "✅ 鎖定 5 個分區代表站點: [500101037, 500103021, 500104112, 500105044, 500106074]\n"
     ]
    }
   ],
   "source": [
    "selected_stations = []\n",
    "station_info_map = {} # Dashboard 專用字典\n",
    "\n",
    "# 檢查是否有行政區欄位\n",
    "if 'district' in df.columns:\n",
    "    districts = df['district'].unique()\n",
    "    print(f\"發現行政區: {districts}\")\n",
    "    \n",
    "    for dist in districts:\n",
    "        # 找出該行政區的所有資料\n",
    "        dist_df = df[df['district'] == dist]\n",
    "        \n",
    "        if not dist_df.empty:\n",
    "            # 找出該區流量最大者 (出現頻率最高)\n",
    "            top_station = dist_df['station_no'].value_counts().idxmax()\n",
    "            selected_stations.append(top_station)\n",
    "            \n",
    "            # 取得真實中文名稱\n",
    "            real_name = name_map.get(str(top_station), f\"{dist}熱門站\")\n",
    "            \n",
    "            # 存入字典： \"500101\": \"捷運科技大樓站 (大安區)\"\n",
    "            station_info_map[str(top_station)] = f\"{real_name} ({dist})\"\n",
    "            \n",
    "    # 取前 5 個不同區域作為代表\n",
    "    top_5_stations = selected_stations[:5]\n",
    "    print(f\" 鎖定 5 個分區代表站點: {top_5_stations}\")\n",
    "\n",
    "else:\n",
    "    print(\"[Error] 資料中找不到 'district' 欄位\")\n",
    "    top_5_stations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151ed7b4-0d3c-4c96-baf3-b4b2916d1aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Mapping: {'500101037': 0, '500103021': 1, '500104112': 2, '500105044': 3, '500106074': 4}\n",
      " 資料過濾與補值完成，剩餘筆數: 12815\n"
     ]
    }
   ],
   "source": [
    "# 只保留 Top 5 站點的資料\n",
    "df_filtered = df[df['station_no'].isin(top_5_stations)].copy()\n",
    "\n",
    "# 建立內部訓練用的 ID Mapping (把站號轉成 0, 1, 2, 3, 4)\n",
    "station_mapping = {str(station): idx for idx, station in enumerate(top_5_stations)}\n",
    "df_filtered['station_idx'] = df_filtered['station_no'].astype(str).map(station_mapping)\n",
    "\n",
    "print(\"Station Mapping:\", station_mapping)\n",
    "\n",
    "# 設定需要補值的特徵 (包含新的 Rain_Cat)\n",
    "features_to_fill = ['bikes_available', 'temperature', 'rain', 'Rain_Cat']\n",
    "\n",
    "# 排序後進行補值 (使用線性插值 + 前後填補)\n",
    "df_filtered = df_filtered.sort_values(['station_idx', 'record_time'])\n",
    "df_filtered[features_to_fill] = df_filtered.groupby('station_idx')[features_to_fill].transform(\n",
    "    lambda x: x.interpolate(method='linear').ffill().bfill()\n",
    ")\n",
    "\n",
    "print(f\" 資料過濾與補值完成，剩餘筆數: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b652760-6788-48af-95f2-803a6a7f609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 序列資料製作完成。Input Shape: torch.Size([12800, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 設定特徵欄位 (共 4 個)\n",
    "feature_cols = ['bikes_available', 'temperature', 'rain', 'Rain_Cat']\n",
    "\n",
    "# 1. 數據縮放 (Scaler)\n",
    "scaler = MinMaxScaler()\n",
    "df_filtered[feature_cols] = scaler.fit_transform(df_filtered[feature_cols])\n",
    "\n",
    "# 2. 製作滑動視窗 (Sliding Window)\n",
    "def create_multistation_dataset(data, time_steps=3):\n",
    "    X_list, y_list = [], []\n",
    "    \n",
    "    for station_idx in data['station_idx'].unique():\n",
    "        station_data = data[data['station_idx'] == station_idx]\n",
    "        \n",
    "        values = station_data[feature_cols].values # 數值特徵\n",
    "        ids = station_data['station_idx'].values   # 站點 ID\n",
    "        \n",
    "        for i in range(len(values) - time_steps):\n",
    "            # 取過去 3 小時的特徵\n",
    "            seq_values = values[i:i+time_steps]\n",
    "            # 取對應的 ID (重塑形狀以利拼接)\n",
    "            seq_ids = ids[i:i+time_steps].reshape(-1, 1)\n",
    "            \n",
    "            # 合併：[特徵(4) + ID(1)] = 5 個欄位\n",
    "            combined_input = np.hstack((seq_values, seq_ids))\n",
    "            \n",
    "            # Label: 下一時刻的 bikes_available\n",
    "            target = values[i + time_steps, 0]\n",
    "            \n",
    "            X_list.append(combined_input)\n",
    "            y_list.append(target)\n",
    "            \n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "# 執行轉換\n",
    "TIME_STEPS = 3\n",
    "X, y = create_multistation_dataset(df_filtered, TIME_STEPS)\n",
    "\n",
    "# 轉成 PyTorch Tensor 並丟進 GPU/CPU\n",
    "X_tensor = torch.FloatTensor(X).to(device)\n",
    "y_tensor = torch.FloatTensor(y).reshape(-1, 1).to(device)\n",
    "\n",
    "print(f\" 序列資料製作完成。Input Shape: {X_tensor.shape}\")\n",
    "# 預期結果: (樣本數, 3, 5) -> 3是時間步, 5是特徵數(4數值+1ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5d3419-2675-47ff-9441-b3c216627925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 模型架構定義完成\n"
     ]
    }
   ],
   "source": [
    "class MultiStationLSTM(nn.Module):\n",
    "    def __init__(self, num_stations, input_size=4, hidden_size=64, output_size=1, embedding_dim=5):\n",
    "        super(MultiStationLSTM, self).__init__()\n",
    "        \n",
    "        # 1. 站點嵌入層 (把 0~4 的 ID 轉成向量)\n",
    "        self.station_embedding = nn.Embedding(num_stations, embedding_dim)\n",
    "        \n",
    "        # 2. LSTM 層\n",
    "        # 輸入維度 = 數值特徵(4) + Embedding(5) = 9\n",
    "        self.lstm_input_size = input_size + embedding_dim\n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # 3. 輸出層\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, 5) \n",
    "        # 切分資料：前4個是數值，最後1個是ID\n",
    "        numerical_features = x[:, :, :4] \n",
    "        station_ids = x[:, :, 4].long()\n",
    "        \n",
    "        # 嵌入運算\n",
    "        station_embedded = self.station_embedding(station_ids)\n",
    "        \n",
    "        # 拼接 (4 + 5 = 9)\n",
    "        combined_input = torch.cat((numerical_features, station_embedded), dim=2)\n",
    "        \n",
    "        # LSTM 運算\n",
    "        out, _ = self.lstm(combined_input)\n",
    "        \n",
    "        # 取最後一個時間點的輸出\n",
    "        out = out[:, -1, :]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "print(\" 模型架構定義完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e68701d-2a39-4fc1-ab43-78c537c2313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 開始訓練模型...\n",
      "Epoch [10/100], Loss: 0.0508\n",
      "Epoch [20/100], Loss: 0.0410\n",
      "Epoch [30/100], Loss: 0.0334\n",
      "Epoch [40/100], Loss: 0.0294\n",
      "Epoch [50/100], Loss: 0.0255\n",
      "Epoch [60/100], Loss: 0.0220\n",
      "Epoch [70/100], Loss: 0.0178\n",
      "Epoch [80/100], Loss: 0.0129\n",
      "Epoch [90/100], Loss: 0.0088\n",
      "Epoch [100/100], Loss: 0.0074\n",
      " 訓練結束！\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "num_stations = len(station_mapping)\n",
    "model = MultiStationLSTM(num_stations=num_stations, input_size=4).to(device)\n",
    "\n",
    "# 設定超參數\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\" 開始訓練模型...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\" 訓練結束！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c53e95-071b-41df-a8e8-e5f493f00402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 所有檔案已儲存至: ../api/model_files\n",
      "包含: model, scaler, mapping, info_map\n"
     ]
    }
   ],
   "source": [
    "save_path = '../api/model_files'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# 1. 儲存模型權重\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'youbike_lstm_multistation.pth'))\n",
    "\n",
    "# 2. 儲存 Scaler (很重要，預測時要用來還原數值)\n",
    "joblib.dump(scaler, os.path.join(save_path, 'scaler.pkl'))\n",
    "\n",
    "# 3. 儲存 站點 ID 對照表 (訓練時的 0,1,2 對應哪個真實站號)\n",
    "joblib.dump(station_mapping, os.path.join(save_path, 'station_mapping.pkl'))\n",
    "\n",
    "# 4. 儲存 Dashboard 顯示資訊 (站號 -> 中文名)\n",
    "joblib.dump(station_info_map, os.path.join(save_path, 'station_info_map.pkl'))\n",
    "\n",
    "print(f\" 所有檔案已儲存至: {save_path}\")\n",
    "print(\"包含: model, scaler, mapping, info_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3405a-78ef-42cd-afb7-9b7dd563998d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (PyTorch)",
   "language": "python",
   "name": "youbike_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
